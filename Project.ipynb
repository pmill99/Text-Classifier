{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import operator\n",
    "import os\n",
    "#Model uses NLTK Snowball word stemmer and standard english NLTK stopwords\n",
    "stemmer = SnowballStemmer('english')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Data from .txt files in each directory\n",
    "<h5>Categories assigned according to the category they were given on cnn.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 2018, D'Ernest Johnson wasn't signed by any...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Brady congratulated Aaron Rodgers for beco...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leading Formula One drivers defended the popul...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greece's Maria Sakkari will make her debut at ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gymnast Simone Biles, who disclosed her mental...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The NBA is facing another incident involving C...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Italian DJ claims he suffered a number of i...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Canadian athletes looking to compete for Team ...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It's not often an NBA star can quietly make hi...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>With 100 race wins and seven world championshi...</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>President Joe Biden faces a number of economic...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Prices on consumer goods are rising in the Uni...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>After a federal judge in Florida struck down t...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nearly 400 million people across 45 cities in ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Federal Reserve announced new trading rule...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Inflation could surge above 5% early next year...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The question of who will regulate cutting-edge...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Financial Stability Oversight Council rele...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>If you're thinking of buying a home or refinan...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Evergrande has made a crucial payment that all...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supply chain bottlenecks are weighing on econo...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>When Amazon opened a sprawling warehouse in he...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>President Joe Biden has for months been circum...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Texas Attorney General Ken Paxton urged the Su...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Voting rights advocates had warned that contro...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\nUkraineâ€™s military took a defiant stand this...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>President Joe Biden said Thursday he would not...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>President Joe Biden said Thursday the US was c...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>President Joe Biden admitted on Thursday that ...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Neera Tanden was named White House staff secre...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The House of Representatives voted on Thursday...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>President Joe Biden said Thursday evening he's...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Justice Department plans to call a US Secr...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The prospects for reaching a tentative agreeme...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Category\n",
       "0   In 2018, D'Ernest Johnson wasn't signed by any...    Sports\n",
       "1   Tom Brady congratulated Aaron Rodgers for beco...    Sports\n",
       "2   Leading Formula One drivers defended the popul...    Sports\n",
       "3   Greece's Maria Sakkari will make her debut at ...    Sports\n",
       "4   Gymnast Simone Biles, who disclosed her mental...    Sports\n",
       "5   The NBA is facing another incident involving C...    Sports\n",
       "6   An Italian DJ claims he suffered a number of i...    Sports\n",
       "7   Canadian athletes looking to compete for Team ...    Sports\n",
       "8   It's not often an NBA star can quietly make hi...    Sports\n",
       "9   With 100 race wins and seven world championshi...    Sports\n",
       "10  President Joe Biden faces a number of economic...  Business\n",
       "11  Prices on consumer goods are rising in the Uni...  Business\n",
       "12  After a federal judge in Florida struck down t...  Business\n",
       "13  Nearly 400 million people across 45 cities in ...  Business\n",
       "14  The Federal Reserve announced new trading rule...  Business\n",
       "15  Inflation could surge above 5% early next year...  Business\n",
       "16  The question of who will regulate cutting-edge...  Business\n",
       "17  The Financial Stability Oversight Council rele...  Business\n",
       "18  If you're thinking of buying a home or refinan...  Business\n",
       "19  Evergrande has made a crucial payment that all...  Business\n",
       "20  Supply chain bottlenecks are weighing on econo...  Business\n",
       "21  When Amazon opened a sprawling warehouse in he...  Business\n",
       "22  President Joe Biden has for months been circum...  Politics\n",
       "23  Texas Attorney General Ken Paxton urged the Su...  Politics\n",
       "24  Voting rights advocates had warned that contro...  Politics\n",
       "25  \\nUkraineâ€™s military took a defiant stand this...  Politics\n",
       "26  President Joe Biden said Thursday he would not...  Politics\n",
       "27  President Joe Biden said Thursday the US was c...  Politics\n",
       "28  President Joe Biden admitted on Thursday that ...  Politics\n",
       "29  Neera Tanden was named White House staff secre...  Politics\n",
       "30  The House of Representatives voted on Thursday...  Politics\n",
       "31  President Joe Biden said Thursday evening he's...  Politics\n",
       "32  The Justice Department plans to call a US Secr...  Politics\n",
       "33  The prospects for reaching a tentative agreeme...  Politics"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing empty dataframe\n",
    "data = pd.DataFrame(columns=[\"Text\", \"Category\"])\n",
    "\n",
    "#Searching for files in directory containing sports articles\n",
    "for file in os.scandir(r\"data\\sports\"):\n",
    "    #Ensuring it is in fact a file\n",
    "    if file.is_file():\n",
    "        #And opening as READONLY if so\n",
    "        f = open(file, 'r')\n",
    "        #Reading the text file and appending it as a sports article to the dataframe\n",
    "        data = data.append({'Text':f.read(), 'Category':'Sports'}, ignore_index=True)\n",
    "\n",
    "#Same process for directory containing business articles\n",
    "for file in os.scandir(r\"data\\business\"):\n",
    "    if file.is_file():\n",
    "        f = open(file, 'r', encoding='UTF-8')\n",
    "        data = data.append({'Text':f.read(), 'Category':'Business'}, ignore_index=True)\n",
    "\n",
    "#And Politics articles\n",
    "for file in os.scandir(r\"data\\politics\"):\n",
    "    if file.is_file():\n",
    "        f = open(file, 'r', encoding='UTF-8')\n",
    "        data = data.append({'Text':f.read(), 'Category':'Politics'}, ignore_index=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions to remove stopwords/punctuation, and stem remaining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and removing stopwords\n",
    "def stopwords_and_stemming(text):\n",
    "    #Splitting text into a list of words\n",
    "    text = text.split()\n",
    "    clean_data = []\n",
    "    #Iterating through word list\n",
    "    for word in text:\n",
    "        if word not in stop_words:\n",
    "            #If it's not a stop word, stem and add to new list\n",
    "            clean_data.append(stemmer.stem(word))\n",
    "    return clean_data\n",
    "\n",
    "#Removing remaining punctuation\n",
    "def remove_punc(words):\n",
    "    new_list = []\n",
    "    #Iterating through word list\n",
    "    for i in words:\n",
    "        #Most punctuation is attached to a word and included in the string\n",
    "        new_string = ''\n",
    "        #Iterating through each character of each word, and removing if it is punctuation\n",
    "        for char in i:\n",
    "            if char.isalnum() and char != '.' and char != ',' and char != \"'\":\n",
    "                new_string += char\n",
    "        new_list.append(new_string)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Text Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier():\n",
    "    def __init__(self, dataset):\n",
    "        #Removing stopwords, punctuation and stemming across dataset\n",
    "        dataset['Text'] = dataset['Text'].apply(stopwords_and_stemming).apply(remove_punc)\n",
    "        #Splitting the given data into test and training groups\n",
    "        txt_train, txt_test, cat_train, cat_test = train_test_split(dataset.Text, dataset.Category, test_size=.2)\n",
    "        #Creating training set and test set for class\n",
    "        self.training_set = pd.DataFrame({'Text':txt_train,'Category':cat_train})\n",
    "        self.test_set = pd.DataFrame({'Text':txt_test,'Category':cat_test})\n",
    "        #Preserving original dataset\n",
    "        self.raw_data = dataset\n",
    "        print('Model Created...')\n",
    "\n",
    "    #Splitting every word of every article into respective categories\n",
    "    def create_training_table(self):\n",
    "        self.training_data_sports = []\n",
    "        self.training_data_business = []\n",
    "        self.training_data_politics = []\n",
    "\n",
    "        #For every list of words (article) in the training set under this category, add it to training_data_[category] list\n",
    "        for article in self.training_set[self.training_set['Category'] == 'Sports'].Text:\n",
    "            self.training_data_sports.extend(article)\n",
    "\n",
    "        for article in self.training_set[self.training_set['Category'] == 'Business'].Text:\n",
    "            self.training_data_business.extend(article)\n",
    "\n",
    "        for article in self.training_set[self.training_set['Category'] == 'Politics'].Text:\n",
    "            self.training_data_politics.extend(article)\n",
    "\n",
    "        print('Training sets created')\n",
    "\n",
    "    #Calculate the conditional probability of a given word belonging to a given category\n",
    "    #i.e. conditional probability of WORD given CATEGORY\n",
    "\n",
    "    def conditional_prob(self, word, category):\n",
    "        if category == 'Sports':\n",
    "            if word in self.training_data_sports:\n",
    "                #Calculate probabililty that given word is in sports category training set\n",
    "                return (self.training_data_sports.count(word)) / len(self.training_data_sports)\n",
    "            else:\n",
    "                return 1\n",
    "        elif category == 'Business':\n",
    "            if word in self.training_data_business:\n",
    "                #Calculate probability for business category\n",
    "                return (self.training_data_business.count(word)) / len(self.training_data_business)\n",
    "            else:\n",
    "                return 1\n",
    "        elif category == 'Politics':\n",
    "            if word in self.training_data_politics:\n",
    "                #For politics category\n",
    "                return (self.training_data_politics.count(word)) / len(self.training_data_politics)\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            return('Invalid Category')\n",
    "    \n",
    "    def predict(self, lst):\n",
    "        #Initializing each probability to 1\n",
    "        bus_prob, sports_prob, poli_prob = 1, 1, 1\n",
    "        #Multiplying conditional probability for each word in test article for each category\n",
    "        for word in lst:\n",
    "            bus_prob *= self.conditional_prob(word, 'Business')\n",
    "            sports_prob *= self.conditional_prob(word, 'Sports')\n",
    "            poli_prob *= self.conditional_prob(word, 'Politics')\n",
    "\n",
    "        #Returning maximum probability of the free\n",
    "        probabilities = {'Sports':sports_prob, 'Business':bus_prob, 'Politics':poli_prob}\n",
    "        return max(probabilities.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    def run(self):\n",
    "        self.create_training_table()\n",
    "        self.test_set['Predicted'] = self.test_set['Text'].apply(self.predict)\n",
    "        num_correct = np.where(self.test_set['Category'] == self.test_set['Predicted'], 1, 0)\n",
    "        print(f'Accuracy: {np.sum(num_correct)/len(self.test_set)}')\n",
    "        print(self.test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created...\n",
      "Training sets created\n",
      "Accuracy: 0.42857142857142855\n",
      "                                                 Text  Category Predicted\n",
      "22  [presid, joe, biden, month, circumspect, descr...  Politics    Sports\n",
      "2   [lead, formula, one, driver, defend, popular, ...    Sports    Sports\n",
      "5   [the, nba, face, anoth, incid, involv, china, ...    Sports    Sports\n",
      "15  [inflat, could, surg, 5, earli, next, year, un...  Business    Sports\n",
      "8   [it, often, nba, star, quiet, make, way, crowd...    Sports    Sports\n",
      "32  [the, justic, depart, plan, call, us, secret, ...  Politics    Sports\n",
      "3   [greec, maria, sakkari, make, debut, wta, fina...    Sports  Politics\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier(data)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Comparing to SKLearn Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing empty dataframe\n",
    "data = pd.DataFrame(columns=[\"Text\", \"Category\"])\n",
    "\n",
    "#Searching for files in directory containing sports articles\n",
    "for file in os.scandir(r\"data\\sports\"):\n",
    "    #Ensuring it is in fact a file\n",
    "    if file.is_file():\n",
    "        #And opening as READONLY if so\n",
    "        f = open(file, 'r', encoding='UTF-8')\n",
    "        #Reading the text file and appending it as a sports article to the dataframe\n",
    "        data = data.append({'Text':f.read(), 'Category':'Sports'}, ignore_index=True)\n",
    "\n",
    "#Same process for directory containing business articles\n",
    "for file in os.scandir(r\"data\\business\"):\n",
    "    if file.is_file():\n",
    "        f = open(file, 'r', encoding='UTF-8')\n",
    "        data = data.append({'Text':f.read(), 'Category':'Business'}, ignore_index=True)\n",
    "\n",
    "#And Politics articles\n",
    "for file in os.scandir(r\"data\\politics\"):\n",
    "    if file.is_file():\n",
    "        f = open(file, 'r', encoding='UTF-8')\n",
    "        data = data.append({'Text':f.read(), 'Category':'Politics'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2857142857142857\n",
      "                                                 Text  Category Predicted\n",
      "22  President Joe Biden has for months been circum...  Politics  Politics\n",
      "5   The NBA is facing another incident involving C...    Sports  Politics\n",
      "20  Supply chain bottlenecks are weighing on econo...  Business  Business\n",
      "6   An Italian DJ claims he suffered a number of i...    Sports  Politics\n",
      "7   Canadian athletes looking to compete for Team ...    Sports  Politics\n",
      "2   Leading Formula One drivers defended the popul...    Sports  Politics\n",
      "3   Greece's Maria Sakkari will make her debut at ...    Sports  Politics\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "test, train = pd.DataFrame(), pd.DataFrame()\n",
    "train['Text'], test['Text'], train['Category'], test['Category'] = train_test_split(data.Text, data.Category, test_size=.2)\n",
    "\n",
    "skmodel = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "skmodel.fit(train['Text'], train['Category'])\n",
    "predicted = skmodel.predict(test['Text'])\n",
    "test['Predicted'] = predicted\n",
    "\n",
    "print(f\"Accuracy: {np.sum(np.where(test['Category'] == test['Predicted'], 1, 0))/len(test)}\")\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caa02fbe39fa2ee16d45552c290d7402c36c73c484e83d2d190ee580e317b9da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
